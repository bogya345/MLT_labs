{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"DJPc0yQwn2sg"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import numpy as n\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39918,"status":"ok","timestamp":1645270997148,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"dA0yKqxHn4xv","outputId":"2d5be3c8-0e57-4e6d-db3a-422f61c12a3a"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":3107,"status":"ok","timestamp":1645271000251,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"sqdMusPZn6Ol","outputId":"30792cc2-9ec1-4735-fa6f-24621f9fccd4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Activity</th>\n","      <th>D1</th>\n","      <th>D2</th>\n","      <th>D3</th>\n","      <th>D4</th>\n","      <th>D5</th>\n","      <th>D6</th>\n","      <th>D7</th>\n","      <th>D8</th>\n","      <th>D9</th>\n","      <th>...</th>\n","      <th>D1767</th>\n","      <th>D1768</th>\n","      <th>D1769</th>\n","      <th>D1770</th>\n","      <th>D1771</th>\n","      <th>D1772</th>\n","      <th>D1773</th>\n","      <th>D1774</th>\n","      <th>D1775</th>\n","      <th>D1776</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.497009</td>\n","      <td>0.10</td>\n","      <td>0.0</td>\n","      <td>0.132956</td>\n","      <td>0.678031</td>\n","      <td>0.273166</td>\n","      <td>0.585445</td>\n","      <td>0.743663</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.366667</td>\n","      <td>0.606291</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.111209</td>\n","      <td>0.803455</td>\n","      <td>0.106105</td>\n","      <td>0.411754</td>\n","      <td>0.836582</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.033300</td>\n","      <td>0.480124</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.209791</td>\n","      <td>0.610350</td>\n","      <td>0.356453</td>\n","      <td>0.517720</td>\n","      <td>0.679051</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.000000</td>\n","      <td>0.538825</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.196344</td>\n","      <td>0.724230</td>\n","      <td>0.235606</td>\n","      <td>0.288764</td>\n","      <td>0.805110</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.100000</td>\n","      <td>0.517794</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.494734</td>\n","      <td>0.781422</td>\n","      <td>0.154361</td>\n","      <td>0.303809</td>\n","      <td>0.812646</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1777 columns</p>\n","</div>"],"text/plain":["   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n","0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n","1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n","2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n","3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n","4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n","\n","         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n","0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n","1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n","2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n","3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n","4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n","\n","   D1774  D1775  D1776  \n","0      0      0      0  \n","1      0      1      0  \n","2      0      0      0  \n","3      0      0      0  \n","4      0      0      0  \n","\n","[5 rows x 1777 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('./data/bioresponse.csv', header=0, sep=',')\n","data.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"uGR1a9BrpHLt"},"outputs":[],"source":["from matplotlib.colors import ListedColormap\n","from sklearn import  datasets, metrics, tree \n","\n","from sklearn.model_selection import  learning_curve\n","from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2P8UcFUYqovt"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"elapsed":390,"status":"ok","timestamp":1645271002014,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"K6idHzYzpEvc","outputId":"eb9d9278-41c3-4983-c5e5-73c855fe940e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(3751, 1776)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>D1</th>\n","      <th>D2</th>\n","      <th>D3</th>\n","      <th>D4</th>\n","      <th>D5</th>\n","      <th>D6</th>\n","      <th>D7</th>\n","      <th>D8</th>\n","      <th>D9</th>\n","      <th>D10</th>\n","      <th>...</th>\n","      <th>D1767</th>\n","      <th>D1768</th>\n","      <th>D1769</th>\n","      <th>D1770</th>\n","      <th>D1771</th>\n","      <th>D1772</th>\n","      <th>D1773</th>\n","      <th>D1774</th>\n","      <th>D1775</th>\n","      <th>D1776</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.000000</td>\n","      <td>0.497009</td>\n","      <td>0.10</td>\n","      <td>0.0</td>\n","      <td>0.132956</td>\n","      <td>0.678031</td>\n","      <td>0.273166</td>\n","      <td>0.585445</td>\n","      <td>0.743663</td>\n","      <td>0.243144</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.366667</td>\n","      <td>0.606291</td>\n","      <td>0.05</td>\n","      <td>0.0</td>\n","      <td>0.111209</td>\n","      <td>0.803455</td>\n","      <td>0.106105</td>\n","      <td>0.411754</td>\n","      <td>0.836582</td>\n","      <td>0.106480</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.033300</td>\n","      <td>0.480124</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.209791</td>\n","      <td>0.610350</td>\n","      <td>0.356453</td>\n","      <td>0.517720</td>\n","      <td>0.679051</td>\n","      <td>0.352308</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.000000</td>\n","      <td>0.538825</td>\n","      <td>0.00</td>\n","      <td>0.5</td>\n","      <td>0.196344</td>\n","      <td>0.724230</td>\n","      <td>0.235606</td>\n","      <td>0.288764</td>\n","      <td>0.805110</td>\n","      <td>0.208989</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.100000</td>\n","      <td>0.517794</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.494734</td>\n","      <td>0.781422</td>\n","      <td>0.154361</td>\n","      <td>0.303809</td>\n","      <td>0.812646</td>\n","      <td>0.125177</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1776 columns</p>\n","</div>"],"text/plain":["         D1        D2    D3   D4        D5        D6        D7        D8  \\\n","0  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166  0.585445   \n","1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105  0.411754   \n","2  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453  0.517720   \n","3  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606  0.288764   \n","4  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361  0.303809   \n","\n","         D9       D10  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n","0  0.743663  0.243144  ...      0      0      0      0      0      0      0   \n","1  0.836582  0.106480  ...      1      1      1      1      0      1      0   \n","2  0.679051  0.352308  ...      0      0      0      0      0      0      0   \n","3  0.805110  0.208989  ...      0      0      0      0      0      0      0   \n","4  0.812646  0.125177  ...      0      0      0      0      0      0      0   \n","\n","   D1774  D1775  D1776  \n","0      0      0      0  \n","1      0      1      0  \n","2      0      0      0  \n","3      0      0      0  \n","4      0      0      0  \n","\n","[5 rows x 1776 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["feats = data.loc[:, data.columns != 'Activity']\n","target = data[\"Activity\"]\n","# feats.sort_values(by='D2').head()\n","print(feats.shape)\n","feats.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"cPaBG6dtnvYB"},"outputs":[],"source":["train_x, test_x, train_y, test_y = train_test_split(feats, target, train_size = .3, random_state = 1)\n","\n","# reshaping data\n","# train_x, test_x, train_y, test_y = np.asarray(train_x).T, np.asarray(test_x).T, np.asarray(train_y).T, np.asarray(test_y).T\n","# train_x, test_x, train_y, test_y = np.asarray(train_x), np.asarray(test_x), np.asarray(train_y), np.asarray(test_y)\n","# train_x, test_x, train_y, test_y = np.asarray(train_x), np.asarray(test_x), np.asarray(train_y), np.asarray(test_y)"]},{"cell_type":"markdown","metadata":{"id":"cat_QnJ4n0T-"},"source":["*   Apply the logistic regression method using the functions in the notebook «Logistic Regression as a Neural Network – BP alg.ipynb” to predict the biological response of a molecule "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Rw1ngJwcqZhn"},"outputs":[],"source":["# activate function\n","def sigmoid(z):\n","    \"\"\"\n","    Compute the sigmoid of z\n","\n","    Arguments:\n","    z -- A scalar or numpy array of any size.\n","\n","    Return:\n","    s -- sigmoid(z)\n","    \"\"\"\n","    \n","    s = 1./(1. + np.exp(-z))\n","    \n","    return s"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-eZPutLrRybf"},"outputs":[],"source":["# initialize weights and bias with zeros\n","\n","def initialize_with_zeros(dim):\n","    \"\"\"\n","    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n","    \n","    Argument:\n","    dim -- size of the w vector we want (or number of parameters in this case)\n","    \n","    Returns:\n","    w -- initialized vector of shape (dim, 1)\n","    b -- initialized scalar (corresponds to the bias)\n","    \"\"\"\n","    \n","    w = np.zeros((dim,1))\n","    b = 0.\n","    \n","    return w, b"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"6-6nwAehR-MY"},"outputs":[],"source":["# propagation\n","\n","def propagate(w, b, X, Y):\n","    \"\"\"\n","    Implement the cost function and its gradient for the propagation explained above\n","\n","    Arguments:\n","    w -- weights, a numpy array of size which equals the number of features\n","    b -- bias, a scalar\n","    X -- data \n","    Y -- true \"label\" vector (containing 0 and 1) of size (1, number of examples)\n","\n","    Return:\n","    cost -- negative log-likelihood cost for logistic regression\n","    dw -- gradient of the loss with respect to w, thus same shape as w\n","    db -- gradient of the loss with respect to b, thus same shape as b\n","    \"\"\"\n","\n","    m = X.shape[1]\n","    # print('number of objects = ', len(X))\n","    \n","    # FORWARD PROPAGATION (FROM X TO COST)\n","    A = sigmoid(np.dot(w.T, X) + b)                                 # compute activation\n","    cost = -(1./m) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A), axis=1)   # compute cost\n","    # print(A)\n","    # print(np.sum(Y * np.log(A) + (1-Y) * np.log(1-A), axis=1))\n","    \n","    # BACKWARD PROPAGATION (TO FIND GRAD)\n","    dw = (1./m) * np.dot(X, (A-Y).T)\n","    db = (1./m) * np.sum(A-Y, axis=1)\n","\n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return grads, cost"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1645271002268,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"Xr_vjFIWSFoH","outputId":"201ae74a-e9b1-4a9c-88f6-dd85f32839a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["dw = [[-0.03931852]\n"," [-0.33046485]\n"," [-0.04613333]\n"," ...\n"," [-0.00533333]\n"," [-0.016     ]\n"," [-0.00888889]]\n","db = [-0.55111111]\n","cost = [44.51213102]\n"]}],"source":["# initializing parameters\n","\n","# w, b, X, Y = np.array([[1.],[-1.]]), 4., np.array([[1.,5.,-1.],[10.,0.,-3.2]]), np.array([[0,1,1]])\n","# w, b, X, Y = np.ones((train_x.shape[1], 1)), 4., train_x.T, train_y\n","# w, b, X, Y = np.random.rand(train_x.shape[1], 1), 4., train_x.T, train_y\n","w, b, X, Y = np.float32(np.random.randint(-1, 1, size=(train_x.shape[1], 1))), 4., np.asarray(train_x).T, np.asarray(train_y)\n","\n","grads, cost = propagate(w, b, X, Y)\n","print(\"dw = \" + str(grads[\"dw\"]))\n","print(\"db = \" + str(grads[\"db\"]))\n","print(\"cost = \" + str(cost))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"hTM2R6XmUUsf"},"outputs":[],"source":["# optimize\n","\n","def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost=False):\n","    \"\"\"\n","    This function optimizes w and b by running a gradient descent algorithm\n","    \n","    Arguments:\n","    w -- weights, a numpy array \n","    b -- bias, a scalar\n","    X -- data \n","    Y -- true \"label\" vector (containing 0 and 1), of shape (1, number of examples)\n","    num_iterations -- number of iterations of the optimization loop\n","    learning_rate -- learning rate of the gradient descent update rule\n","    print_cost -- True to print the loss every 100 steps\n","    \n","    Returns:\n","    params -- dictionary containing the weights w and bias b\n","    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n","    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n","    \n","    \"\"\"\n","    \n","    costs = []\n","    \n","    for i in range(num_iterations):\n","                \n","        # Cost and gradient calculation \n","        grads, cost = propagate(w, b, X, Y)\n","        \n","        # Retrieve derivatives from grads\n","        dw = grads[\"dw\"]\n","        db = grads[\"db\"]\n","        \n","        # update rule\n","        w -= learning_rate * dw\n","        b -= learning_rate * db\n","        \n","        # Record the costs\n","        if i % 100 == 0:\n","            costs.append(cost)\n","        \n","        # Print the cost every 100 training iterations\n","        if print_cost and i % 100 == 0:\n","            print(\"Cost after iteration %i: %f\" %(i, cost))\n","    \n","    params = {\"w\": w,\n","              \"b\": b}\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return params, grads, costs"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6165,"status":"ok","timestamp":1645271008429,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"kYS8NPBK_uxf","outputId":"1f706ebe-df97-4aa4-f6b6-b705018f8cfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cost after iteration 0: 44.512131\n","Cost after iteration 100: 35.736767\n","Cost after iteration 200: 26.961958\n","Cost after iteration 300: 18.304459\n","Cost after iteration 400: 12.328420\n","Cost after iteration 500: 10.039721\n","Cost after iteration 600: 8.792908\n","Cost after iteration 700: 7.830621\n","Cost after iteration 800: 7.008163\n","Cost after iteration 900: 6.307782\n","w = [[-0.87577474]\n"," [-0.31291023]\n"," [ 0.14738564]\n"," ...\n"," [-0.9733567 ]\n"," [ 0.07999965]\n"," [-0.95553493]]\n","b = [5.0390782]\n","dw = [[-0.0119096 ]\n"," [ 0.00964766]\n"," [-0.01313821]\n"," ...\n"," [-0.00533333]\n"," [-0.016     ]\n"," [-0.00888889]]\n","db = [0.04758723]\n"]}],"source":["params, grads, costs = optimize(w, b, X, Y, num_iterations= 1000, learning_rate = 0.005, print_cost = True)\n","\n","print (\"w = \" + str(params[\"w\"]))\n","print (\"b = \" + str(params[\"b\"]))\n","print (\"dw = \" + str(grads[\"dw\"]))\n","print (\"db = \" + str(grads[\"db\"]))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"B9CXVjSNUwnn"},"outputs":[],"source":["# predict\n","\n","def predict(w, b, X):\n","    '''\n","    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n","    \n","    Arguments:\n","    w -- weights, a numpy array \n","    b -- bias, a scalar\n","    X -- data \n","    \n","    Returns:\n","    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n","    '''\n","    \n","    m = X.shape[1]\n","    Y_prediction = np.zeros((1, m))\n","    w = w.reshape(X.shape[0], 1)\n","    \n","    # Compute vector \"A\" predicting the probabilities \n","    A = sigmoid(np.dot(w.T,X) + b)\n","    \n","    for i in range(A.shape[1]):\n","        \n","        # Convert probabilities A[0,i] to actual predictions p[0,i]\n","        if (A[0,i] <= 0.5):\n","            Y_prediction[0][i] = 0\n","        else:\n","            Y_prediction[0][i] = 1\n","    \n","    return Y_prediction"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1645271008430,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"2IWYLbr6Un7y","outputId":"20921172-3153-4bbe-cbbd-dcb281007c49"},"outputs":[{"name":"stdout","output_type":"stream","text":["predictions = [[1. 1. 1. ... 1. 1. 1.]]\n"]}],"source":["# w = np.array([[0.1124579], [0.23106775]])\n","w = np.random.rand(np.asarray(train_x).shape[1], 1)\n","b = -0.3\n","# X = np.array([[1.,-1.1,-3.2], [1.2,2.,0.1]])\n","X = train_x.T\n","print (\"predictions = \" + str(predict(w, b, X)))"]},{"cell_type":"markdown","metadata":{"id":"dCTmQrs-pfQC"},"source":["*   Modify optimize() function to implement the stochastic gradient descent (SGD) method. Apply it to solve the problem from p.1."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"QdWEtHiBpx5m"},"outputs":[],"source":["# optimize\n","\n","def optimize2(w, b, train_x, train_y, num_iterations, learning_rate, print_cost=False):\n","    \"\"\"\n","    This function optimizes w and b by running a gradient descent algorithm\n","    \n","    Arguments:\n","    w -- weights, a numpy array \n","    b -- bias, a scalar\n","    X -- data \n","    Y -- true \"label\" vector (containing 0 and 1), of shape (1, number of examples)\n","    num_iterations -- number of iterations of the optimization loop\n","    learning_rate -- learning rate of the gradient descent update rule\n","    print_cost -- True to print the loss every 100 steps\n","    \n","    Returns:\n","    params -- dictionary containing the weights w and bias b\n","    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n","    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n","    \n","    \"\"\"\n","\n","    X = pd.DataFrame(train_x)\n","    Y = pd.DataFrame(train_y)\n","    XY = X.join(Y)\n","\n","    costs = []\n","    \n","    for i in range(num_iterations):\n","\n","        # choose randomly the number\n","        # rand = np.random.randint(0, X.shape[1] - 10)\n","        rand = np.random.randint(0, X.shape[0])\n","        XYs = XY.sample(rand)\n","\n","        Xs = XYs.loc[:, XYs.columns != 'Activity']\n","        Ys = XYs[\"Activity\"]\n","\n","        Xs = np.asarray(Xs)\n","        Ys = np.asarray(Ys)\n","        \n","        # Cost and gradient calculation (with random data)\n","        # grads, cost = propagate(w, b, X[rand, :].reshape(1, -1), Y[rand])\n","        # grads, cost = propagate(w, b, X[rand:rand + 10].reshape(1, -1), Y[rand:rand + 10])\n","        grads, cost = propagate(w, b, Xs.T, Ys)\n","        # grads, cost = propagate(w, b, X[:, rand:rand], Y[rand:rand])\n","        \n","        # Retrieve derivatives from grads\n","        dw = grads[\"dw\"]\n","        db = grads[\"db\"]\n","        \n","        # update rule\n","        w -= learning_rate * dw\n","        b -= learning_rate * db\n","        \n","        # Record the costs\n","        if i % 100 == 0:\n","            costs.append(cost)\n","        \n","        # Print the cost every 100 training iterations\n","        if print_cost and i % 100 == 0:\n","            print(\"Cost after iteration %i: %f\" %(i, cost))\n","    \n","    params = {\"w\": w,\n","              \"b\": b}\n","    \n","    grads = {\"dw\": dw,\n","             \"db\": db}\n","    \n","    return params, grads, costs"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1645271008798,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"jeOT48z2WcIE","outputId":"d533e0fb-cf74-402a-be7c-14792492780f"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Unic-ITMO\\ML\\_proj\\.venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","c:\\Unic-ITMO\\ML\\_proj\\.venv\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in multiply\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]}],"source":["m = X.shape[1]\n","A = sigmoid(np.dot(w.T, X) + b)                                 # compute activation\n","cost = -(1./m) * np.sum(Y * np.log(A) + (1-Y) * np.log(1-A), axis=1)   # compute cost"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1645271008799,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"2-od_8TsUiMV","outputId":"56573b23-a854-4d12-9708-907f6ab2e527"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>w</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [w]\n","Index: []"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["W = pd.DataFrame(w, columns=['w'])\n","# W[ (W['w'] > -0.001) & (W['w'] < 0.001) ]\n","W[ W['w'] == -1 ]"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19151,"status":"ok","timestamp":1645271525776,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"ADfXmK4b8QIb","outputId":"18df67a4-bc44-478a-d702-edfb507d4eb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cost after iteration 0: 2.799492\n","Cost after iteration 100: 2.043708\n","Cost after iteration 200: 1.933116\n","Cost after iteration 300: 1.786150\n","Cost after iteration 400: 1.629336\n","Cost after iteration 500: 1.524314\n","Cost after iteration 600: 1.570584\n","Cost after iteration 700: 1.499186\n","Cost after iteration 800: 1.434562\n","Cost after iteration 900: 1.421534\n","w = [[-0.17781889]\n"," [-0.3745971 ]\n"," [-0.38089442]\n"," ...\n"," [-0.47844517]\n"," [-0.4304268 ]\n"," [ 0.76039172]]\n","b = [2.82601807]\n","dw = [[ 0.00248967]\n"," [-0.01336651]\n"," [-0.00437849]\n"," ...\n"," [ 0.00390627]\n"," [ 0.00649332]\n"," [ 0.0041454 ]]\n","db = [-0.02203526]\n"]}],"source":["# w, b = np.float32(np.random.randint(-1, 1, size=(train_x.shape[1], 1))), 4.\n","w, b = np.random.uniform(-1, 1, size=(train_x.shape[1], 1)), 3.\n","params, grads, costs = optimize2(w, b, train_x, train_y, num_iterations = 1000, learning_rate = 0.005, print_cost = True)\n","\n","print(\"w = \" + str(params[\"w\"]))\n","print(\"b = \" + str(params[\"b\"]))\n","print(\"dw = \" + str(grads[\"dw\"]))\n","print(\"db = \" + str(grads[\"db\"]))"]},{"cell_type":"markdown","metadata":{"id":"adgvyUq9pgeH"},"source":["*   For two modifications of gradient descent (pp. 1 and 2), plot the learning curves (dependence of the value of the loss function on the iteration number), apply models with different values ​​of the learning rate (at least 5 different learning rates). How does it affect the accuracy of the model? "]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5646,"status":"ok","timestamp":1645271540567,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"Ok8ZieMZd6fh","outputId":"3ca3bb24-fd0b-4829-83df-d1dac21babc4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cost after iteration 0: 43.510303\n","Cost after iteration 100: 34.734932\n","Cost after iteration 200: 25.959637\n","Cost after iteration 300: 17.315943\n","Cost after iteration 400: 11.991316\n","Cost after iteration 500: 10.021497\n","Cost after iteration 600: 8.883377\n","Cost after iteration 700: 7.912975\n","Cost after iteration 800: 7.028434\n","Cost after iteration 900: 6.263975\n","w = [[ 0.11692814]\n"," [ 0.66311127]\n"," [ 0.1485543 ]\n"," ...\n"," [ 0.02666695]\n"," [ 0.07999965]\n"," [-0.95553493]]\n","b = [3.98618516]\n","dw = [[-0.01040738]\n"," [ 0.00607262]\n"," [-0.01549204]\n"," ...\n"," [-0.00533333]\n"," [-0.016     ]\n"," [-0.00888889]]\n","db = [0.04273539]\n"]}],"source":["# optimize 1\n","w, b, X, Y = np.float32(np.random.randint(-1, 1, size=(train_x.shape[1], 1))), 3., np.asarray(train_x).T, np.asarray(train_y)\n","params1, grads1, costs1 = optimize(w, b, X, Y, num_iterations = 1000, learning_rate = 0.005, print_cost = True)\n","\n","print (\"w = \" + str(params1[\"w\"]))\n","print (\"b = \" + str(params1[\"b\"]))\n","print (\"dw = \" + str(grads1[\"dw\"]))\n","print (\"db = \" + str(grads1[\"db\"]))"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15259,"status":"ok","timestamp":1645271610551,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"In68YDaId_TS","outputId":"25e3522a-3f0b-4fa0-89ff-3ed7a03a1c2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cost after iteration 0: 2.466679\n","Cost after iteration 100: 2.348602\n","Cost after iteration 200: 2.340681\n","Cost after iteration 300: 2.222989\n","Cost after iteration 400: 2.170738\n","Cost after iteration 500: 2.470621\n","Cost after iteration 600: 2.141257\n","Cost after iteration 700: 1.673734\n","Cost after iteration 800: 2.084721\n","Cost after iteration 900: 2.052989\n","w = [[ 0.55247958]\n"," [-0.45442586]\n"," [-0.72734332]\n"," ...\n"," [-0.03100613]\n"," [-0.37316261]\n"," [-0.4573621 ]]\n","b = [2.95372166]\n","dw = [[ 0.00953935]\n"," [ 0.03411755]\n"," [-0.00230751]\n"," ...\n"," [ 0.00071538]\n"," [-0.00618252]\n"," [-0.00353811]]\n","db = [0.05501378]\n"]}],"source":["# optimize 2\n","# w, b = np.float32(np.random.randint(-1, 1, size=(train_x.shape[1], 1))), 4.\n","# w, b = np.random.randn(-1, 1, size=(train_x.shape[1], 1)), 4.\n","# w, b = np.random.rand(train_x.shape[1], 1)*10, 4.\n","w, b = np.random.uniform(-1, 1, size=(train_x.shape[1], 1)), 3.\n","params2, grads2, costs2 = optimize2(w, b, train_x, train_y, num_iterations = 1000, learning_rate = 0.0005, print_cost = True)\n","\n","print(\"w = \" + str(params2[\"w\"]))\n","print(\"b = \" + str(params2[\"b\"]))\n","print(\"dw = \" + str(grads2[\"dw\"]))\n","print(\"db = \" + str(grads2[\"db\"]))"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"elapsed":731,"status":"ok","timestamp":1645271846342,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"qkhbwGu7hpeD","outputId":"3515d487-ae95-42f2-b723-0c58e4849d9b"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["plt.plot(costs1)\n","plt.plot(costs2)\n","plt.legend(['costs1 (optimize1 GD)','costs2 (optimize2 SGD)'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"IxPvLnS1pyUo"},"source":["- Implement the Adam optimization method using the numpy library and compare the accuracy of the model fitted with it with the models trained by the classic GD and SGD algorithms"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1645272782340,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"hhUBiP4Tp0ew"},"outputs":[],"source":["class AdamOptim():\n","\n","    def __init__(self, eta=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n","        self.m_dw, self.v_dw = 0, 0\n","        self.m_db, self.v_db = 0, 0\n","        self.beta1 = beta1\n","        self.beta2 = beta2\n","        self.epsilon = epsilon\n","        self.eta = eta\n","        pass\n","\n","    def update(self, t, w, b, dw, db):\n","        ## dw, db are from current mini-batch\n","        ## momentum beta 1\n","        # *** weights *** #\n","        self.m_dw = self.beta1*self.m_dw + (1-self.beta1)*dw\n","        # *** biases *** #\n","        self.m_db = self.beta1*self.m_db + (1-self.beta1)*db\n","\n","        ## rms beta 2\n","        # *** weights *** #\n","        self.v_dw = self.beta2*self.v_dw + (1-self.beta2)*(dw**2)\n","        # *** biases *** #\n","        self.v_db = self.beta2*self.v_db + (1-self.beta2)*(db)\n","\n","        ## bias correction\n","        m_dw_corr = self.m_dw/(1-self.beta1**t)\n","        m_db_corr = self.m_db/(1-self.beta1**t)\n","        v_dw_corr = self.v_dw/(1-self.beta2**t)\n","        v_db_corr = self.v_db/(1-self.beta2**t)\n","\n","        ## update weights and biases\n","        w = w - self.eta*(m_dw_corr/(np.sqrt(v_dw_corr)+self.epsilon))\n","        b = b - self.eta*(m_db_corr/(np.sqrt(v_db_corr)+self.epsilon))\n","        return w, b\n","        \n","    def show_info(self):\n","      oround = lambda args, digits=5: round(args, digits) if (type(args) in (int, float, complex) ) else [round(i, digits) for i in args]\n","      info = {\n","        'm_dw':     oround(self.m_dw),\n","        'v_dw':     oround(self.v_dw),\n","        'm_db':     oround(self.m_db),\n","        'v_db':     oround(self.v_db),\n","        'beta1':    oround(self.beta1),\n","        'beta2':    oround(self.beta2), \n","        'epsilon':  oround(self.epsilon),\n","        'eta':      oround(self.eta)\n","      }\n","      print(info)\n","      return info"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":755,"status":"error","timestamp":1645275916572,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"87FRYCAL-v0b","outputId":"84cad0aa-9ee2-449e-eca3-df276ab56a11"},"outputs":[{"ename":"ValueError","evalue":"operands could not be broadcast together with shapes (1776,1125) (1125,1125) ","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9876\\1729144222.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mw_0_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw_0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mw_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiComparing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_0_old\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9876\\2551101492.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, t, w, b, dw, db)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m## update weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_dw_corr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_dw_corr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_db_corr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv_db_corr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1776,1125) (1125,1125) "]}],"source":["eta = 0.1\n","epsilon = 1e-1\n","adam = AdamOptim(eta=eta, epsilon=epsilon)\n","\n","w_0, b_0 = np.random.uniform(-1, 1, size=(train_x.shape[1], 1)), 3.\n","\n","t = 1\n","\n","prev_dif = 0\n","\n","# grad_vector = lambda args: [*args]\n","grad_vector = lambda args: sigmoid(np.dot(args.T, X))\n","\n","multiComparing = lambda args1, args2: [(np.round(a1, 20) == np.round(a2, 20)) for a1, a2 in zip(args1, args2)]\n","\n","while True:\n","\n","    dw = grad_vector(w_0)\n","    db = b_0\n","\n","    w_0_old = w_0\n","    w_0, b_0 = adam.update(t, w=w_0, b=b_0, dw=dw, db=db)\n","\n","    if (np.any(multiComparing(w_0, w_0_old))):\n","        print('converged after '+str(t)+' iterations')\n","        break\n","    else:\n","        # adam.show_info()\n","        # print('iteration '+str(t)+': weight='+str(w_0), 'bias='+str(b_0)+'\\n')\n","        t+=1\n","        pass\n","\n","    continue\n","\n","print(w_0)\n","print(b_0)\n","adam.show_info()"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMLeEQ5d+IQ76dlq7EdeSRg","collapsed_sections":[],"name":"Volkov_Bogdan_J41321c_MLT_2022_Lab3.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}
