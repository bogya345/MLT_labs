{"cells":[{"cell_type":"markdown","metadata":{"id":"OAqC8xXmZ1Av"},"source":["## Convolutional Neural Network \n","\n"]},{"cell_type":"markdown","metadata":{"id":"3z8CfGD5Z1Ay"},"source":["In this notebook you will learn to distinguish dogs from cats!\n","\n","Data:\n","https://drive.google.com/drive/folders/1nzVk4GOvKR6P87uPszUkKMPtaXV_wrZf?usp=sharing\n","\n","Fill all the necessary gaps in cells below and fit neural networks for solving the binary classification task.\n","\n","## Task 1:\n","\n","1. Build and fit CNN with 3 convolutional layers for binary classification\n","2. Evaluate accuracy on test data\n","3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n","\n","First, let's load all the necessary functions:\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":194,"status":"ok","timestamp":1645340031819,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"HyzNnZpdZ1A4"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n","# from keras.applications import VGG16\n","from keras.applications import vgg16\n","# from keras.optimizers import Adam\n","from keras.optimizers import adam_v2\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"DS-6t0_XZ1BL"},"source":["The images collected for training and testing the deep learning model must be prepared: split the entire set into a training, validation and test sample, observing the balancing of classes (with binary classification they should be approximately equal in all three samples).\n","\n","This has _already_ been done: in the Cats_and_Dogs directory there are three subdirectories: train, test and val - training, test and validation samples, respectively."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19896,"status":"ok","timestamp":1645340051923,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"iK6VqL9Abk9v","outputId":"6f255f46-96b5-4249-e735-62da72393fc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["# # if you are using google colab for this task you can mount your GoogleDrive as follows: \n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","# # After running this cell you should enter the authorization code from your Google account"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645341381899,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"Ejt0NSnVZ1BP"},"outputs":[],"source":["# Initialize the folders with train, test and validation datasets (in \"/My Drive/...\" or from your local repository where you have downloaded data):\n","\n","train = './data/Lab5/train'\n","val =   './data/Lab5/val'\n","test =  './data/Lab5/test'\n","\n","\n","# The shape of the RGB image\n","img_width, img_height, channels = 150, 150, 3 # you can try different sizes\n","\n","# input shape\n","input_shape = (img_width, img_height, 3)\n","# position matters!\n","# Number_of_channels can be at the first or the last position\n","# in our case - \"channels last\"\n","\n","# minibatch size\n","batch_size = 64\n","# train set size\n","nb_train_samples = 10\n","# validation set size \n","nb_validation_samples = 5\n","# test set size\n","nb_test_samples = 5"]},{"cell_type":"markdown","metadata":{"id":"rYe-jLGbZ1Bh"},"source":["## Prepare the data.\n","\n","You don’t have to manually change the shapes of 25000 images and convert them into the necessary format for keras (img_width, img_height, 3).\n","\n","We will use the built-in image preprocessing function _ImageGenerator()_.\n","\n","It performs scaling, resizes selected images and prepares batches (mini-samples) to train the model."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"elapsed":199,"status":"error","timestamp":1645341351043,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"Ncx9lh6LZ1Bk","outputId":"056b9af3-6f6d-45d2-8cd5-d3437ed8e2bd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 20000 images belonging to 2 classes.\n","Found 2490 images belonging to 2 classes.\n","Found 2500 images belonging to 2 classes.\n"]}],"source":["datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","train_generator = datagen.flow_from_directory(\n","    train,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","val_generator = datagen.flow_from_directory(\n","    val,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","test_generator = datagen.flow_from_directory(\n","    test,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1645340051924,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"MRvSz7oXZ1B2"},"outputs":[{"ename":"TypeError","evalue":"'DirectoryIterator' object is not callable","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17544\\86100725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use generator for training the model (\"fit\" method analog)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.fit_generator(\n","\u001b[1;31mTypeError\u001b[0m: 'DirectoryIterator' object is not callable"]}],"source":["# use generator for training the model (\"fit\" method analog)\n","\n","model = train_generator()\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples // batch_size,\n","    epochs=10,\n","    validation_data=val_generator,\n","    validation_steps=nb_validation_samples // batch_size)"]},{"cell_type":"markdown","metadata":{"id":"GthRQyZHZ1CI"},"source":["Set the network architecture by sequentially adding layers to it:\n","1. A convolutional layer with 16 neurons, filter size 3x3. Activation function - 'relu'\n","2. MaxPooling layer with filter size 2x2.\n","3. A convolutional layer with 32 neurons, filter size 3x3. Activation function - 'relu'\n","4. MaxPooling layer with filter size 2x2.\n","5. A convolutional layer with 64 neurons, filter size 3x3. Activation function - 'relu'\n","6. MaxPooling layer with filter size 2x2.\n","7. Operation model.add (Flatten ()), which makes a one-dimensional vector of the resulting feature maps.\n","8. A fully connected layer with 64 neurons. Activation function - 'relu'\n","9. Use model.add (Dropout (0.5)) which excludes the edge from the current layer in the computational graph with a 50% probability to avoid overfitting.\n","10. A fully connected layer with 1 neuron. Activation function - 'sigmoid', because binary classification model.\n","\n","Add to the model all the missing layers, by analogy with the already specified.\n","Keras documentation: https://keras.io/layers/about-keras-layers/"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1645340051925,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"yNik7qzRZ1CU"},"outputs":[],"source":["model = Sequential()\n","\n","# 1: +Convolutional\n","# For example:\n","model.add(Conv2D(16, (3, 3), input_shape=(150, 150, 3)))\n","model.add(Activation('relu'))\n","\n","# 2: +Pooling\n","# 3:\n","model.add(Conv2D(32, (3, 3)))\n","#     +Relu\n","\n","# 4:  +Pooling \n","# 5:  +Convolutional\n","#     +Relu\n","# 6:  +Pooling \n","# 7:  +Flattening\n","# 8:  +Dense\n","#     +ReLu\n","# 9:  +Dropout\n","# 10: +Dense\n","#     +Sigmoid\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1645340051925,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"0nNS5cLjZ1Cg"},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1645340051925,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"BzqPxMJdZ1Cu"},"outputs":[],"source":["# use the generator to train the model (analogue of the fit method)\n","# 1 epoch of training on a CPU will take 4-6 minutes. The GPU is an ~order of magnitude faster.\n","# THE FIRST EPOCH USUALLY TAKES MUCH LARGER TIME AS KERAS SHOULD BUILD THE COMPUTATIONAL GRAPH\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples // batch_size,\n","    epochs=, # try different number of epochs: 10, 15, 20; check the loss and accuracy;\n","    validation_data=val_generator,\n","    validation_steps=nb_validation_samples // batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1645340051926,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"KBMrJqBHZ1DT"},"outputs":[],"source":["# NOTE: if the accuracy on test data after 15 epochs is less than 80% smth goes wrong\n","\n","scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n","print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"]},{"cell_type":"markdown","metadata":{"id":"Mle_LO6XMJ62"},"source":["Plot the graphs: \n","\n","- Loss(Number of epochs)\n","\n","- Accuracy(Number of epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1645340051926,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"icBG1BT0WVSE"},"outputs":[],"source":["import matplotlib.image as mpimg\n","import matplotlib.pyplot as plt\n","img = mpimg.imread('/content/drive/My Drive/ITMO/ML/Lab5/Deeper.jpeg')\n","plt.figure(figsize = (10,20))\n","plt.imshow(img)\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"QESIOnCPZ1Dz"},"source":["Let's try to improve the quality of recognition, using the method of transfer lerning. \n","\n","We will use weights of deep neural networks already trained on large dataset such as  ImageNet, and provide fine tuning of several additional dense layers on new data relevant to the current classification task. The more new images will differ from those on which the network has been trained, the more layers will need to be “retrained” in order to get good classification accuracy. The intuition here is that the model has already learned how to highlight the necessary features on the images in the large dataset, it only needs to be “tweaked” for a specific task.\n","\n","## Task 2\n","\n","1. Build and fit Transfer Learning model using pre-trained VGG16-model weights from keras application.\n","2. Do the same with **another avaliable pre-trained deep learning model** from keras application https://keras.io/api/applications/.\n","2. Evaluate accuracy on test data for p.1 and p.2\n","3. Plot the graphs for Loss(number_of_epochs) and Accuracy(number_of_epochs)\n","4. Check the performance of your model with the custom image of cat or dog (so the model will tell which class this image belongs to). Develop the function for the inference of the best algorithm."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1645340051927,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"Md_9fT-nZ1D2"},"outputs":[],"source":["# First, download the weights of the VGG16 network trained on the ImageNet dataset:\n","\n","vgg16_net = VGG16(weights='imagenet', \n","                  include_top=False,      # we take only the \"convolution\" part, the last layers we add ourselves\n","                  input_shape=(150, 150, 3))\n","vgg16_net.trainable = False               # clearly prescribe that we do NOT overload the network.\n","                                          # Weights VGG16 in the process of learning will remain unchanged!\n","\n","vgg16_net.summary()                       # pay attention to the number of trained and untrained parameters"]},{"cell_type":"markdown","metadata":{"id":"a_DTDXqWZ1EG"},"source":["We construct our model of \"transfer learning\" by adding two fully connected layers to VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1645340051927,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"hKYlhGqTZ1EJ"},"outputs":[],"source":["# add layers to VGG16:\n","\n","model = Sequential()\n","model.add(vgg16_net)\n","\n","# + flattening\n","# + Dense fullyconnected layer with 256 neurons\n","# + ReLu\n","# + Dropout\n","# + Dense layer with 1 neuron\n","# + sigmoid\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1645340051928,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"hKU1pQEeZ1Ea"},"outputs":[],"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(lr=1e-5), \n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"ZxBZMbzAZ1Ex"},"source":["E.g., it was like:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1645340051928,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"MKMm7XjBXWJi"},"outputs":[],"source":["img = mpimg.imread('./data/Lab5/VGG16.png')\n","plt.figure(figsize = (10,20))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XAPd3c7SZ1FP"},"source":["and it becomes:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1645340051928,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"P8Llp_iqXSu5"},"outputs":[],"source":["img = mpimg.imread('./data/Lab5/VGG162.png')\n","plt.figure(figsize = (10,20))\n","plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1645340051928,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"gNX7L-MIZ1FX"},"outputs":[],"source":["# We also use the generator to train the model (similar to the fit method)\n","# Without using a GPU, learning 1 epoch of such a network will take about an hour. Plan your time =)\n","# If you have access to a GPU, you can try 10-12 epochs - the quality should increase even more.\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples // batch_size,\n","    epochs=5,\n","    validation_data=val_generator,\n","    validation_steps=nb_validation_samples // batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1645340051929,"user":{"displayName":"Bogdan Volkov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiiYCs2znIfq0mJ-UKdp3QUUr6FeezPv1uYhl_a=s64","userId":"11299140811716513852"},"user_tz":-180},"id":"vMCxq21YZ1Fh"},"outputs":[],"source":["scores = model.evaluate_generator(test_generator, nb_test_samples // batch_size)\n","print(\"Accuracy on test data: %.2f%%\" % (scores[1]*100))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"CNN_and_Transfer_Learning.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}
